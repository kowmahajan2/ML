{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prototype code for model making",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnTstV802mtK"
      },
      "source": [
        "# GAN overriding `Model.train_step`\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2019/04/29<br>\n",
        "**Last modified:** 2020/04/29<br>\n",
        "**Description:** A simple DCGAN trained using `fit()` by overriding `train_step`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pepLX91q2mtK"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eieajSuj2mtK"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as mlp\n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOMbVR-H1oiF",
        "outputId": "63d18d98-bc53-4c18-a257-5491022ada8c"
      },
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "class Item:\n",
        "    properties = []\n",
        "\n",
        "    def __init__(self, proplist):\n",
        "        self.properties = proplist\n",
        "\n",
        "    def developProps(self):\n",
        "        self.index = int(self.properties[0][1])\n",
        "\n",
        "        self.voxelPos = []\n",
        "        cut = self.properties[3][1].find(\" \")\n",
        "        i = 0\n",
        "        self.voxelPos.append(int(self.properties[3][1][i:cut]))\n",
        "        i = cut\n",
        "        cut = self.properties[3][1].find(\" \", cut + 1)\n",
        "        self.voxelPos.append(int(self.properties[3][1][i:cut]))\n",
        "        self.voxelPos.append(int(self.properties[3][1][cut+1:]))\n",
        "\n",
        "        self.angles = []\n",
        "        cut = self.properties[5][1].find(\" \")\n",
        "        i = 0\n",
        "        self.angles.append(int(self.properties[5][1][i:cut]))\n",
        "        i = cut\n",
        "        cut = self.properties[5][1].find(\" \", cut + 1)\n",
        "        self.angles.append(int(self.properties[5][1][i:cut]))\n",
        "        self.angles.append(int(self.properties[5][1][cut+1:]))\n",
        "                \n",
        "    \n",
        "    def printprops(self):\n",
        "        print(self.properties)\n",
        "        print(self.voxelPos)\n",
        "        print(self.angles)\n",
        "\n",
        "class Connection:\n",
        "\n",
        "    def __init__(self, proplist):\n",
        "        self.properties = proplist\n",
        "    \n",
        "    def printprops(self):\n",
        "        print(self.properties)\n",
        "\n",
        "class Voxel:\n",
        "    def __init__(self, solid, portal0, portal1, portal2):\n",
        "        self.solid = solid\n",
        "        self.portal0 = portal0\n",
        "        self.portal1 = portal1\n",
        "        self.portal2 = portal2\n",
        "        self.itemList = []\n",
        "        self.oneHotItem = []\n",
        "    \n",
        "    def setSolid(self, solid):\n",
        "        self.solid = solid\n",
        "    \n",
        "    def setPortal0(self, portal0):\n",
        "        self.portal0 = portal0\n",
        "\n",
        "    def setPortal1(self, portal1):\n",
        "        self.portal1 = portal1\n",
        "\n",
        "    def setPortal2(self, portal2):\n",
        "        self.portal2 = portal2\n",
        "    \n",
        "    def addItem(self,newItem):\n",
        "        self.itemList.append(newItem)\n",
        "\n",
        "    def printVoxel(self):\n",
        "        print(self.solid)\n",
        "    \n",
        "    def enterVoxel(self):\n",
        "        ret = [self.solid, self.portal0, self.portal1, self.portal2] + self.oneHotItem\n",
        "        return ret\n",
        "    \n",
        "    def makeOneHot(self):\n",
        "        self.oneHotItem = [1,0,0,0,0,0]\n",
        "        for i in self.itemList:\n",
        "            if(i.properties[1][1] == \"ITEM_ENTRY_DOOR\"):\n",
        "                self.oneHotItem = [0,1,0,0,0,0]\n",
        "            elif(i.properties[1][1] == \"ITEM_EXIT_DOOR\"):\n",
        "                self.oneHotItem = [0,0,1,0,0,0]\n",
        "            elif(i.properties[1][1] == \"ITEM_CUBE\"):\n",
        "                self.oneHotItem = [0,0,0,1,0,0]\n",
        "            elif(i.properties[1][1] == \"ITEM_DROPPER_CUBE\"):\n",
        "                self.oneHotItem = [0,0,0,0,1,0]\n",
        "            elif(i.properties[1][1] == \"ITEM_BUTTON_FLOOR\"):\n",
        "                self.oneHotItem = [0,0,0,0,0,1]\n",
        "    \n",
        "                \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "class Level:\n",
        "    def __init__(self):\n",
        "        self.voxelArray = []\n",
        "        self.size = []\n",
        "        self.itemArray = []\n",
        "        self.connectionArray =[]\n",
        "        self.limits = 10\n",
        "    \n",
        "    def printLevel(self):\n",
        "        for i in range(0,15):  \n",
        "            for j in range(0,15):\n",
        "                for k in range(0,15):\n",
        "                    Z.voxelArray[i][j][k].printVoxel()\n",
        "\n",
        "    def LevelRead(self,name):\n",
        "        level = open(name, 'r+b')\n",
        "        x = 0\n",
        "        y = 0\n",
        "        z = 0\n",
        "\n",
        "\n",
        "        for line in level:\n",
        "            if(str(line).find(\"ChamberSize\") != -1):\n",
        "                tempLine = line\n",
        "                letter = tempLine[17:18]\n",
        "                i = 17\n",
        "                while(letter != b\" \"):\n",
        "                    x = x*10 + int(letter.decode(\"utf-8\"))\n",
        "                    i = i + 1\n",
        "                    letter = tempLine[i:i+1]\n",
        "                i = i + 1\n",
        "                letter = tempLine[i:i+1]\n",
        "                while(letter != b\" \"):\n",
        "                    y = y*10 + int(letter.decode(\"utf-8\"))\n",
        "                    i = i + 1\n",
        "                    letter = tempLine[i:i+1]\n",
        "                i = i + 1\n",
        "                letter = tempLine[i:i+1]\n",
        "                while(letter != b'\"'):\n",
        "                    z = z*10 + int(letter.decode(\"utf-8\"))\n",
        "                    i = i + 1\n",
        "                    letter = tempLine[i:i+1]\n",
        "                break\n",
        "\n",
        "        #print(x)\n",
        "        #print(y)\n",
        "        #print(z)\n",
        "        self.size = [x,y,z]\n",
        "        X = []\n",
        "        Y = []\n",
        "        Z = []\n",
        "        for i in range(0,self.limits):\n",
        "            for j in range(0,self.limits):\n",
        "                for k in range(0,self.limits):\n",
        "                    X.append(Voxel(1,1,1,1))\n",
        "                Y.append(X)\n",
        "                X = []\n",
        "            Z.append(Y)\n",
        "            Y = []\n",
        "        \n",
        "        #print(np.shape(Z))\n",
        "        \n",
        "        \"\"\"for line in level:\n",
        "            \n",
        "            if((str(line).find(\"Solid\") != -1)):\n",
        "                for line in level:\n",
        "                    tempLine = line\n",
        "                    print(tempLine)\n",
        "                    if(str(tempLine).find(\"f\") != -1):\n",
        "                        i = 12\n",
        "                        #print(i)\n",
        "                        letter = tempLine[i:i+1]\n",
        "                        while(letter != b'\"'):\n",
        "                            print(letter)\n",
        "                            X.append(Voxel(int(letter.decode(\"utf-8\")),1,1,1))\n",
        "                            i = i + 1\n",
        "                            letter = tempLine[i:i+1]\n",
        "                        #print(\"Length of X\" + str(len(X)))\n",
        "                        Y.append(X)\n",
        "                        X = []\n",
        "                    elif(str(tempLine).find(\"}\") != -1):\n",
        "                        #print(\"Length of Y\" + str(len(Y)))\n",
        "                        Z.append(Y)\n",
        "                        Y = []\n",
        "                    elif(str(tempLine).find(\"Portal0\") != -1):\n",
        "                        #print(len(Z))\n",
        "                        break\"\"\"\n",
        "                \n",
        "        xIter = 0\n",
        "        yIter = 0\n",
        "        zIter = 0\n",
        "        #solid\n",
        "        for line in level:\n",
        "            tempLine = line\n",
        "            #print(tempLine)\n",
        "            if(str(tempLine).find(\"f\") != -1):\n",
        "                i = 12\n",
        "                #print(i)\n",
        "                letter = tempLine[i:i+1]\n",
        "                while(letter != b'\"'):\n",
        "                    #print(letter)\n",
        "                    Z[zIter][yIter][xIter].setSolid(int(letter.decode(\"utf-8\")))\n",
        "                    xIter = xIter + 1\n",
        "                    i = i + 1\n",
        "                    letter = tempLine[i:i+1]\n",
        "                #print(\"Length of X\" + str(len(X)))\n",
        "                yIter = yIter + 1\n",
        "                xIter = 0\n",
        "            elif(str(tempLine).find(\"}\") != -1):\n",
        "                #print(\"Length of Y\" + str(len(Y)))\n",
        "                zIter = zIter + 1\n",
        "                yIter = 0\n",
        "            elif(str(tempLine).find(\"Portal0\") != -1):\n",
        "                #print(len(Z))\n",
        "                break\n",
        "\n",
        "        xIter = 0\n",
        "        yIter = 0\n",
        "        zIter = 0\n",
        "        #portal0\n",
        "        for line in level:\n",
        "            tempLine = line\n",
        "            #print(tempLine)\n",
        "            if(str(tempLine).find(\"f\") != -1):\n",
        "                i = 12\n",
        "                #print(i)\n",
        "                letter = tempLine[i:i+1]\n",
        "                while(letter != b'\"'):\n",
        "                    #print(letter)\n",
        "                    Z[zIter][yIter][xIter].setPortal0(int(letter.decode(\"utf-8\")))\n",
        "                    xIter = xIter + 1\n",
        "                    i = i + 1\n",
        "                    letter = tempLine[i:i+1]\n",
        "                #print(\"Length of X\" + str(len(X)))\n",
        "                yIter = yIter + 1\n",
        "                xIter = 0\n",
        "            elif(str(tempLine).find(\"}\") != -1):\n",
        "                #print(\"Length of Y\" + str(len(Y)))\n",
        "                zIter = zIter + 1\n",
        "                yIter = 0\n",
        "            elif(str(tempLine).find(\"Portal1\") != -1):\n",
        "                #print(len(Z))\n",
        "                break\n",
        "        \n",
        "        xIter = 0\n",
        "        yIter = 0\n",
        "        zIter = 0\n",
        "        #portal1\n",
        "        for line in level:\n",
        "            tempLine = line\n",
        "            #print(tempLine)\n",
        "            if(str(tempLine).find(\"f\") != -1):\n",
        "                i = 12\n",
        "                #print(i)\n",
        "                letter = tempLine[i:i+1]\n",
        "                while(letter != b'\"'):\n",
        "                    #print(letter)\n",
        "                    Z[zIter][yIter][xIter].setPortal1(int(letter.decode(\"utf-8\")))\n",
        "                    xIter = xIter + 1\n",
        "                    i = i + 1\n",
        "                    letter = tempLine[i:i+1]\n",
        "                #print(\"Length of X\" + str(len(X)))\n",
        "                yIter = yIter + 1\n",
        "                xIter = 0\n",
        "            elif(str(tempLine).find(\"}\") != -1):\n",
        "                #print(\"Length of Y\" + str(len(Y)))\n",
        "                zIter = zIter + 1\n",
        "                yIter = 0\n",
        "            elif(str(tempLine).find(\"Portal2\") != -1):\n",
        "                #print(len(Z))\n",
        "                break\n",
        "\n",
        "        xIter = 0\n",
        "        yIter = 0\n",
        "        zIter = 0\n",
        "        #portal2\n",
        "        for line in level:\n",
        "            tempLine = line\n",
        "            #print(tempLine)\n",
        "            if(str(tempLine).find(\"f\") != -1):\n",
        "                i = 12\n",
        "                #print(i)\n",
        "                letter = tempLine[i:i+1]\n",
        "                while(letter != b'\"'):\n",
        "                    #print(letter)\n",
        "                    Z[zIter][yIter][xIter].setPortal2(int(letter.decode(\"utf-8\")))\n",
        "                    xIter = xIter + 1\n",
        "                    i = i + 1\n",
        "                    letter = tempLine[i:i+1]\n",
        "                #print(\"Length of X\" + str(len(X)))\n",
        "                yIter = yIter + 1\n",
        "                xIter = 0\n",
        "            elif(str(tempLine).find(\"}\") != -1):\n",
        "                #print(\"Length of Y\" + str(len(Y)))\n",
        "                zIter = zIter + 1\n",
        "                yIter = 0\n",
        "            elif(str(tempLine).find(\"Items\") != -1):\n",
        "                #print(len(Z))\n",
        "                break\n",
        "        \n",
        "        #print(line)\n",
        "        self.voxelArray = copy.deepcopy(Z)\n",
        "\n",
        "        itemList = []\n",
        "        connectionList = []\n",
        "\n",
        "        itemPropList = []\n",
        "        prop = \"\"\n",
        "        value = \"\"\n",
        "        propTupple = []\n",
        "\n",
        "                #iterating over all the lines\n",
        "        \n",
        "        for line in level:\n",
        "            #print(line)\n",
        "            #print(\"hey\")\n",
        "            #clearing property and value strings at the start of each line\n",
        "            prop = \"\"\n",
        "            value = \"\"\n",
        "\n",
        "            #check if the string contains \"Item\" and not \"Items\"\n",
        "            if((str(line).find(\"Item\") != -1) and (str(line).find(\"Items\") == -1)):\n",
        "                \n",
        "                itemPropList = []\n",
        "                for line in level:\n",
        "                    tempLine = line\n",
        "                    prop = \"\"\n",
        "                    value = \"\"\n",
        "                    propTupple = []\n",
        "                    i = 0\n",
        "                    #if line contains \"{\" do nothing\n",
        "                    if(str(tempLine).find(\"{\")!= -1):\n",
        "                        pass\n",
        "                        #print(\"do nothing\")\n",
        "                    elif(str(tempLine).find(\"}\")!= -1):\n",
        "                        if(len(itemPropList) > 0):\n",
        "                            newItem = Item(itemPropList)\n",
        "                            newItem.developProps()\n",
        "                            \"\"\"print(len(self.voxelArray))\n",
        "                            print(len(self.voxelArray[0]))\n",
        "                            print(len(self.voxelArray[0][0]))\n",
        "                            print(len(newItem.voxelPos))\"\"\"\n",
        "                            #print(newItem.voxelPos)\n",
        "                            self.voxelArray[newItem.voxelPos[2]][newItem.voxelPos[1]][newItem.voxelPos[0]].itemList.append(newItem)\n",
        "                            itemList.append(newItem)\n",
        "                            itemPropList = []\n",
        "                            break\n",
        "                    else:\n",
        "\n",
        "                        #skipping the 3 tabs and the inverted comma\n",
        "                        letter = tempLine[4:5]\n",
        "                        i = 4\n",
        "                        #recording the string uptill the next inverted comma\n",
        "                        while(letter != b'\"'):\n",
        "                            prop = \"\".join([prop, letter.decode(\"utf-8\")])\n",
        "                            i = i + 1\n",
        "                            letter = tempLine[i:i+1]\n",
        "                        \n",
        "                        #skipping the 2 tabs uptill the next inverted comma\n",
        "                        i = i + 4\n",
        "                        letter = tempLine[i:i+1]\n",
        "\n",
        "                        #recording the string uptill the next inverted comma\n",
        "                        while(letter != b'\"'):\n",
        "                            \n",
        "                            value = \"\".join([value, letter.decode(\"utf-8\")])\n",
        "                            i = i+1\n",
        "                            letter = tempLine[i:i+1]\n",
        "                        \n",
        "                        \n",
        "\n",
        "                        \n",
        "                        #print(prop)\n",
        "                        #print(value)\n",
        "                        propTupple.append(prop)\n",
        "                        propTupple.append(value)\n",
        "                \n",
        "                #adding property to the current list\n",
        "                        itemPropList.append(propTupple)\n",
        "\n",
        "                self.itemArray = copy.deepcopy(itemList)\n",
        "\n",
        "                        \n",
        "\n",
        "                #restting the property tupple\n",
        "            if((str(line).find(\"Connection\") != -1) and (str(line).find(\"Connections\") == -1)):\n",
        "                \n",
        "                connectionPropList = []\n",
        "                for line in level:\n",
        "                    tempLine = line\n",
        "                    prop = \"\"\n",
        "                    value = \"\"\n",
        "                    propTupple = []\n",
        "                    i = 0\n",
        "                    #if line contains \"{\" do nothing\n",
        "                    if(str(tempLine).find(\"{\")!= -1):\n",
        "                        pass\n",
        "                        #print(\"do nothing\")\n",
        "                    elif(str(tempLine).find(\"}\")!= -1):\n",
        "                        if(len(connectionPropList) > 0):\n",
        "                            newConnection = Connection(connectionPropList)\n",
        "                            connectionList.append(newConnection)\n",
        "                            connectionPropList = []\n",
        "                            break\n",
        "                    else:\n",
        "\n",
        "                        #skipping the 3 tabs and the inverted comma\n",
        "                        letter = tempLine[4:5]\n",
        "                        i = 4\n",
        "                        #recording the string uptill the next inverted comma\n",
        "                        while(letter != b'\"'):\n",
        "                            prop = \"\".join([prop, letter.decode(\"utf-8\")])\n",
        "                            i = i + 1\n",
        "                            letter = tempLine[i:i+1]\n",
        "                        \n",
        "                        #skipping the 2 tabs uptill the next inverted comma\n",
        "                        i = i + 4\n",
        "                        letter = tempLine[i:i+1]\n",
        "\n",
        "                        #recording the string uptill the next inverted comma\n",
        "                        while(letter != b'\"'):\n",
        "                            \n",
        "                            value = \"\".join([value, letter.decode(\"utf-8\")])\n",
        "                            i = i+1\n",
        "                            letter = tempLine[i:i+1]\n",
        "                        \n",
        "                        \n",
        "\n",
        "                        \n",
        "                        #print(prop)\n",
        "                        #print(value)\n",
        "                        propTupple.append(prop)\n",
        "                        propTupple.append(value)\n",
        "                \n",
        "                #adding property to the current list\n",
        "                        connectionPropList.append(propTupple)\n",
        "                self.connectionArray = copy.deepcopy(connectionList)\n",
        "\n",
        "        #print(len(itemList))\n",
        "        #print(len(connectionList))\n",
        "        #itemList[2].printprops()\n",
        "    \n",
        "        \n",
        "    def developOneHot(self):\n",
        "        for i in range(0,self.limits):\n",
        "            for j in range(0,self.limits):\n",
        "                for k in range(0,self.limits):\n",
        "                    self.voxelArray[i][j][k].makeOneHot()\n",
        "\n",
        "    def makeCSVarray(self):\n",
        "        Z = []\n",
        "        Y = []\n",
        "        X = []\n",
        "        for i in range(0,self.limits):\n",
        "            for j in range(0,self.limits):\n",
        "                for k in range(0,self.limits):\n",
        "                    X.append(self.voxelArray[i][j][k].enterVoxel())\n",
        "                Y.append(X)\n",
        "                X = []\n",
        "            Z.append(Y)\n",
        "            Y = []\n",
        "        return Z\n",
        "    \n",
        "        \n",
        "\n",
        "data = []\n",
        "\n",
        "for k in range(0,38):\n",
        "    print(k)\n",
        "    name = \"level (\" +str(k + 1) + \").p2c\"\n",
        "    newLevel = Level()\n",
        "    newLevel.LevelRead(name)\n",
        "    newLevel.developOneHot()\n",
        "    Z = newLevel.makeCSVarray()\n",
        "    data.append(Z)\n",
        "    data.append(np.rot90(Z,1,(1,2)))\n",
        "    data.append(np.rot90(Z,2,(1,2)))\n",
        "    data.append(np.rot90(Z,3,(1,2)))\n",
        "    data.append(np.flip(Z,1))\n",
        "    data.append(np.rot90(np.flip(Z,1),1,(1,2)))\n",
        "    data.append(np.rot90(np.flip(Z,1),2,(1,2)))\n",
        "    data.append(np.rot90(np.flip(Z,1),3,(1,2)))\n",
        "    del newLevel\n",
        "\n",
        "print(np.shape(data))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "(304, 10, 10, 10, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO-daVxi2mtK"
      },
      "source": [
        "## Prepare MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_HKAEMV2mtK"
      },
      "source": [
        "# We use both the training & test MNIST digits.\n",
        "batch_size = 50\n",
        "\n",
        "\"\"\"(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255\"\"\"\n",
        "#all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "#data = pd.read_csv('Data.csv')\n",
        "#print(data)\n",
        "#Z = np.array(data)\n",
        "#print(np.shape(Z))\n",
        "dataN = np.array(data)\n",
        "dataN = dataN.astype(\"float32\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBpxBUn7rrwT",
        "outputId": "ef8124a6-d087-47b3-d71b-4608c6996c87"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(dataN)\n",
        "dataset = dataset.shuffle(buffer_size=10).batch(batch_size)\n",
        "print(dataset)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: (None, 10, 10, 10, 10), types: tf.float32>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8miFVRW2mtL"
      },
      "source": [
        "## Create the discriminator\n",
        "\n",
        "It maps 28x28 digits to a binary classification score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "dLFCYA1w2mtL",
        "outputId": "8e17bdb6-2fc0-4889-d374-39e56265ad1b"
      },
      "source": [
        "\"\"\"discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "discriminator.summary()\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'discriminator = keras.Sequential(\\n    [\\n        keras.Input(shape=(28, 28, 1)),\\n        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.GlobalMaxPooling2D(),\\n        layers.Dense(1),\\n    ],\\n    name=\"discriminator\",\\n)\\n\\ndiscriminator.summary()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HOR1y9J3Y0z",
        "outputId": "52fcdf78-b850-458c-812d-a2b38504ae59"
      },
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(10, 10, 10, 10)), \n",
        "        layers.Conv3D(16, (3, 3, 3), strides=(1, 1, 1), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv3D(32, (3, 3, 3), strides=(2, 2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv3D(64, (3, 3, 3), strides=(2, 2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling3D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_3 (Conv3D)            (None, 10, 10, 10, 16)    4336      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 10, 10, 10, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 5, 5, 5, 32)       13856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 5, 5, 5, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 3, 3, 3, 64)       55360     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 3, 3, 3, 64)       0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling3d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 73,617\n",
            "Trainable params: 73,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq5ZoZBU2mtL"
      },
      "source": [
        "## Create the generator\n",
        "\n",
        "It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwqQEjBJ2mtL",
        "outputId": "c566e611-ef57-4a75-fe43-2882c7f02572"
      },
      "source": [
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "        layers.Dense(3* 3 * 3 * 64),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((3, 3, 3, 64)),\n",
        "        layers.Conv3DTranspose(32, (4, 4, 4), strides=(2, 2, 2), padding=\"same\"),\n",
        "        layers.Cropping3D(cropping = ((0,1),(0,1),(0,1))),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv3DTranspose(16, (4, 4, 4), strides=(2, 2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv3DTranspose(10, (4, 4, 4), strides=(1, 1, 1), padding=\"same\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1728)              222912    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 1728)              0         \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 3, 3, 3, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_12 (Conv3DT (None, 6, 6, 6, 32)       131104    \n",
            "_________________________________________________________________\n",
            "cropping3d_2 (Cropping3D)    (None, 5, 5, 5, 32)       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 5, 5, 5, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_13 (Conv3DT (None, 10, 10, 10, 16)    32784     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 10, 10, 10, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_14 (Conv3DT (None, 10, 10, 10, 10)    10250     \n",
            "=================================================================\n",
            "Total params: 397,050\n",
            "Trainable params: 397,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjpoHSZA2mtL"
      },
      "source": [
        "## Override `train_step`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpc9v7du1lH5"
      },
      "source": [
        "def makelevel(levelarray):\n",
        "  for i in range(0,10):\n",
        "    for j in range(0,10):\n",
        "      for k in range(0,10):\n",
        "        for l in range(0,4):\n",
        "          if(levelarray[i][j][k][l] >= 0.5):\n",
        "             levelarray[i][j][k][l] = 1.0\n",
        "          else:\n",
        "            levelarray[i][j][k][l] = 0.0\n",
        "        maxind = np.argmax(levelarray[i][j][k][4:10])+4\n",
        "        print(maxind)\n",
        "        for l in range(4,10):\n",
        "          if(l == maxind):\n",
        "            levelarray[i][j][k][l] = 1.0\n",
        "          else:\n",
        "            levelarray[i][j][k][l] = 0.0\n",
        "  return levelarray\n",
        "          "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb6asfLH2mtL"
      },
      "source": [
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "\n",
        "        # Combine them with real images\n",
        "        \n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTHa1EcG2mtL"
      },
      "source": [
        "## Create a callback that periodically saves generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuiwev1d2mtL"
      },
      "source": [
        "\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images.numpy()\n",
        "        generated_images = np.reshape(generated_images,(-1,10*10*10,10))\n",
        "        for i in range(self.num_img):\n",
        "            df = pd.DataFrame(generated_images[i])\n",
        "            df.to_csv(\"Data\" + str(epoch)+str(i)+\".csv\", index = False)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKWLX8L42mtL"
      },
      "source": [
        "## Train the end-to-end model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmxfuNXO2mtL",
        "outputId": "fe866f0b-c7da-4a47-a407-f4f1dd6d300a"
      },
      "source": [
        "epochs = 50\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    \n",
        ")\n",
        "\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=1, latent_dim=latent_dim)]\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 5s 682ms/step - d_loss: 0.5306 - g_loss: 0.6619\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 5s 673ms/step - d_loss: 0.5518 - g_loss: 0.5201\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 5s 672ms/step - d_loss: 0.5151 - g_loss: 0.7645\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 5s 670ms/step - d_loss: 0.4150 - g_loss: 1.1812\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 5s 676ms/step - d_loss: 0.6220 - g_loss: 0.6150\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 5s 672ms/step - d_loss: 0.5169 - g_loss: 0.9559\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 5s 677ms/step - d_loss: 0.2678 - g_loss: 1.3678\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 5s 672ms/step - d_loss: 0.3210 - g_loss: 0.9998\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 5s 679ms/step - d_loss: 0.4214 - g_loss: 0.6757\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 5s 677ms/step - d_loss: 0.4216 - g_loss: 0.7272\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 5s 674ms/step - d_loss: 0.3588 - g_loss: 0.9528\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 5s 675ms/step - d_loss: 0.2787 - g_loss: 1.2075\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 5s 677ms/step - d_loss: 0.2899 - g_loss: 1.1995\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 5s 678ms/step - d_loss: 0.3727 - g_loss: 0.9504\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 5s 679ms/step - d_loss: 0.3748 - g_loss: 0.9823\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 5s 677ms/step - d_loss: 0.2440 - g_loss: 1.3868\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 5s 673ms/step - d_loss: 0.2374 - g_loss: 1.2530\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 5s 675ms/step - d_loss: 0.2362 - g_loss: 1.2691\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 5s 675ms/step - d_loss: 0.2398 - g_loss: 1.2029\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 5s 680ms/step - d_loss: 0.2220 - g_loss: 1.3182\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 5s 678ms/step - d_loss: 0.2225 - g_loss: 1.2864\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 5s 678ms/step - d_loss: 0.2180 - g_loss: 1.3177\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 5s 679ms/step - d_loss: 0.1840 - g_loss: 1.5492\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 5s 678ms/step - d_loss: 0.1062 - g_loss: 2.3309\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 5s 676ms/step - d_loss: 0.0641 - g_loss: 2.9312\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 5s 681ms/step - d_loss: 0.0889 - g_loss: 2.4154\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 5s 675ms/step - d_loss: 0.1275 - g_loss: 2.1097\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 5s 684ms/step - d_loss: 0.0964 - g_loss: 3.0219\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 5s 675ms/step - d_loss: 0.2046 - g_loss: 3.5990\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 5s 676ms/step - d_loss: 0.5388 - g_loss: 3.9224\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 5s 672ms/step - d_loss: 0.2834 - g_loss: 5.7152\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 5s 682ms/step - d_loss: 1.6788 - g_loss: 1.3266\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 5s 677ms/step - d_loss: 0.8579 - g_loss: 2.3521\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 5s 681ms/step - d_loss: 0.8430 - g_loss: 1.6206\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 5s 677ms/step - d_loss: 1.5046 - g_loss: 0.4251\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 5s 677ms/step - d_loss: 0.1546 - g_loss: 3.3134\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 5s 679ms/step - d_loss: 0.0585 - g_loss: 3.3795\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 5s 678ms/step - d_loss: 0.0702 - g_loss: 2.6499\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 5s 679ms/step - d_loss: 0.1075 - g_loss: 2.2549\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 5s 679ms/step - d_loss: 0.1162 - g_loss: 2.0758\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 5s 678ms/step - d_loss: 0.1304 - g_loss: 1.9365\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 5s 681ms/step - d_loss: 0.2422 - g_loss: 1.3695\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 5s 679ms/step - d_loss: 0.4699 - g_loss: 1.1506\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 5s 674ms/step - d_loss: 0.3531 - g_loss: 1.9106\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 5s 673ms/step - d_loss: 0.2505 - g_loss: 2.4706\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 5s 670ms/step - d_loss: 0.5077 - g_loss: 3.0722\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 5s 678ms/step - d_loss: 0.1648 - g_loss: 4.9740\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 5s 676ms/step - d_loss: 1.8709 - g_loss: 0.8109\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 5s 675ms/step - d_loss: 0.4501 - g_loss: 2.8297\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 5s 680ms/step - d_loss: 0.0640 - g_loss: 4.5682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLdL7jmN2mtL"
      },
      "source": [
        "Display the last generated images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "OFnSBEXn2mtL",
        "outputId": "1598e822-a4fb-441e-d82e-045f9d111f65"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(\"generated_img_0_29.png\"))\n",
        "display(Image(\"generated_img_1_29.png\"))\n",
        "display(Image(\"generated_img_2_29.png\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "generated_img_0_29.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "generated_img_1_29.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "generated_img_2_29.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-GUaZd-RFnO",
        "outputId": "3e6e4504-a957-44a2-9605-991bbd902321"
      },
      "source": [
        "dataN = pd.read_csv('Data390.csv')\n",
        "\n",
        "print(dataN)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0         1         2  ...         7         8         9\n",
            "0    0.245842  0.300074  0.318715  ...  0.044053  0.154267  0.081534\n",
            "1    0.318418  0.297599  0.197076  ...  0.044738  0.194486  0.139605\n",
            "2    0.295285  0.261154  0.247458  ...  0.111277  0.246358  0.155012\n",
            "3    0.311800  0.215596  0.178139  ...  0.068990  0.245509  0.087855\n",
            "4    0.294532  0.320489  0.194850  ...  0.110331  0.243785  0.129305\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "995  0.367233  0.375169 -0.087441  ...  0.412348  0.459979  0.077910\n",
            "996  0.499175  0.262587  0.007857  ...  0.363846  0.405592  0.083995\n",
            "997  0.376846  0.447463 -0.051831  ...  0.398915  0.416886  0.098570\n",
            "998  0.647582  0.532102  0.153664  ...  0.439212  0.551390  0.167340\n",
            "999  0.440778  0.499609  0.069000  ...  0.395202  0.442006  0.090233\n",
            "\n",
            "[1000 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX0LuFriguf1",
        "outputId": "bcca6d26-8b5a-4eb2-e0db-638a2ce8ad83"
      },
      "source": [
        "Z = np.array(dataN)\n",
        "Z =  np.reshape(Z,(10,10,10,10))\n",
        "finalevel = makelevel(Z)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "4\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "4\n",
            "4\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "4\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "4\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "5\n",
            "8\n",
            "7\n",
            "7\n",
            "5\n",
            "7\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "5\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "5\n",
            "7\n",
            "7\n",
            "5\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "8\n",
            "8\n",
            "5\n",
            "5\n",
            "8\n",
            "5\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "4\n",
            "6\n",
            "5\n",
            "5\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "4\n",
            "4\n",
            "4\n",
            "6\n",
            "4\n",
            "7\n",
            "8\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "9\n",
            "5\n",
            "5\n",
            "5\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "5\n",
            "5\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "4\n",
            "5\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "5\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "4\n",
            "4\n",
            "8\n",
            "4\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "7\n",
            "7\n",
            "9\n",
            "7\n",
            "7\n",
            "8\n",
            "9\n",
            "6\n",
            "6\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "5\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "6\n",
            "4\n",
            "4\n",
            "4\n",
            "6\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "4\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "9\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "4\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "7\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "5\n",
            "7\n",
            "5\n",
            "5\n",
            "5\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "8\n",
            "7\n",
            "7\n",
            "6\n",
            "7\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "5\n",
            "7\n",
            "8\n",
            "5\n",
            "5\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "7\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy6IPTOBihqt"
      },
      "source": [
        "finalevel = np.reshape(finalevel,(10*10*10,10))\n",
        "df = pd.DataFrame(finalevel)\n",
        "df.to_csv(\"finalevel.csv\", index = False)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWJF-l8ukFfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7e6c2aba-4475-497d-cb10-736aef8b92d3"
      },
      "source": [
        "mlp.plot(history.history['d_loss'])\r\n",
        "mlp.plot(history.history['g_loss'])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7fe3c62ac8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKK9ExXkVMFd",
        "outputId": "94416753-9ee7-42b4-d5f0-e28d77ff5a67"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['d_loss', 'g_loss'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UIEsioNVkYj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}